{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Spam/Ham SMS Classifier**"
      ],
      "metadata": {
        "id": "7kV1UEVvDdzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "FPHE_oeHDb9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI6wS1VoAgp1",
        "outputId": "7d2e4f6f-3a94-4f5d-cf55-4ecf99286c0d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset"
      ],
      "metadata": {
        "id": "wr9Q2HtTDW10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/kaggle/input/sms-spam-collection-dataset/spam.csv', encoding='latin-1')\n",
        "\n",
        "# Display the first few rows\n",
        "print(data.head())\n",
        "\n",
        "# Check for missing values and basic info\n",
        "print(data.info())\n",
        "print(data['v1'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp1aaa9tAhVD",
        "outputId": "58c2ff63-9491-4227-ab25-e2e42cd4cead"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     v1                                                 v2 Unnamed: 2  \\\n",
            "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
            "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
            "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
            "\n",
            "  Unnamed: 3 Unnamed: 4  \n",
            "0        NaN        NaN  \n",
            "1        NaN        NaN  \n",
            "2        NaN        NaN  \n",
            "3        NaN        NaN  \n",
            "4        NaN        NaN  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   v1          5572 non-null   object\n",
            " 1   v2          5572 non-null   object\n",
            " 2   Unnamed: 2  50 non-null     object\n",
            " 3   Unnamed: 3  12 non-null     object\n",
            " 4   Unnamed: 4  6 non-null      object\n",
            "dtypes: object(5)\n",
            "memory usage: 217.8+ KB\n",
            "None\n",
            "v1\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean the dataset"
      ],
      "metadata": {
        "id": "nNib5dfdDPPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns (if present)\n",
        "data = data[['v1', 'v2']]\n",
        "\n",
        "# Rename columns for clarity\n",
        "data.columns = ['label', 'message']\n",
        "\n",
        "# Convert labels to binary (ham: 0, spam: 1)\n",
        "data['label'] = data['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Check the distribution of spam vs. ham\n",
        "print(data['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJJq_uIRAl8L",
        "outputId": "bcb94489-ff61-489c-cabc-6c4dca172e00"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "0    4825\n",
            "1     747\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-159413f8bfa9>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['label'] = data['label'].map({'ham': 0, 'spam': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess the Text Data"
      ],
      "metadata": {
        "id": "UaRaqHDtDIWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize stemmer and stopwords\n",
        "ps = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove special characters and digits\n",
        "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stopwords and stem\n",
        "    tokens = [ps.stem(word) for word in tokens if word not in stop_words]\n",
        "    # Join tokens back into a string\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing to the message column\n",
        "data['processed_message'] = data['message'].apply(preprocess_text)\n",
        "\n",
        "# View a few processed messages\n",
        "print(data[['message', 'processed_message']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwYT5gswAwcv",
        "outputId": "9e6ab005-64f3-4e4f-ea9d-4be7c6e6724e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             message  \\\n",
            "0  Go until jurong point, crazy.. Available only ...   \n",
            "1                      Ok lar... Joking wif u oni...   \n",
            "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
            "3  U dun say so early hor... U c already then say...   \n",
            "4  Nah I don't think he goes to usf, he lives aro...   \n",
            "\n",
            "                                   processed_message  \n",
            "0  go jurong point crazi avail bugi n great world...  \n",
            "1                              ok lar joke wif u oni  \n",
            "2  free entri wkli comp win fa cup final tkt st m...  \n",
            "3                u dun say earli hor u c alreadi say  \n",
            "4               nah think goe usf live around though  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction"
      ],
      "metadata": {
        "id": "J9MIElOSDFbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize TF-IDF vectorizer\n",
        "tfidf = TfidfVectorizer(max_features=5000)  # Limit to top 5000 features\n",
        "\n",
        "# Transform the processed text into TF-IDF features\n",
        "X = tfidf.fit_transform(data['processed_message']).toarray()\n",
        "y = data['label']\n",
        "\n",
        "# Check the shape of the feature matrix\n",
        "print(X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahUo_gC3A0bT",
        "outputId": "9eb1a5f9-709b-4652-8059-3345ee30432f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5572, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the Data"
      ],
      "metadata": {
        "id": "gaGPMAS1DCZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape}\")\n",
        "print(f\"Testing set size: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQzmudeHBTgB",
        "outputId": "da36f6bb-e67c-4a13-9e4f-9383e73783bf"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: (4457, 5000)\n",
            "Testing set size: (1115, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a Model"
      ],
      "metadata": {
        "id": "jxGg3S9oC_9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiIOxaeGBV0Y",
        "outputId": "85edd77f-15a1-4556-db3f-10bc5234f5f7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.968609865470852\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       965\n",
            "           1       1.00      0.77      0.87       150\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.88      0.93      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[965   0]\n",
            " [ 35 115]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle Imbalanced Data"
      ],
      "metadata": {
        "id": "mt4SrJPOC802"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Retrain the model\n",
        "model.fit(X_train_res, y_train_res)\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy after SMOTE:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report after SMOTE:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ph11j51yBX4v",
        "outputId": "b9ce4d7f-5a1f-4c44-8974-188bcd6a88ed"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after SMOTE: 0.9668161434977578\n",
            "\n",
            "Classification Report after SMOTE:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98       965\n",
            "           1       0.83      0.95      0.88       150\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.91      0.96      0.93      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test with New Data"
      ],
      "metadata": {
        "id": "nf4THJSQC03t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sms(text, model, tfidf):\n",
        "    # Preprocess the input text\n",
        "    processed_text = preprocess_text(text)\n",
        "    # Transform using the same TF-IDF vectorizer\n",
        "    text_vector = tfidf.transform([processed_text]).toarray()\n",
        "    # Predict\n",
        "    prediction = model.predict(text_vector)\n",
        "    return 'Spam' if prediction[0] == 1 else 'Ham'\n",
        "\n",
        "# Test with a sample message\n",
        "sample_text = \"Free entry to win $1000! Click now!\"\n",
        "print(predict_sms(sample_text, model, tfidf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijBp_QVyBgu_",
        "outputId": "b81c59f9-a9fe-4cc3-ff38-689b4fb9e0e3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the Model and Vectorizer"
      ],
      "metadata": {
        "id": "DJdU1It6Cw8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model and vectorizer\n",
        "joblib.dump(model, 'spam_classifier_model.pkl')\n",
        "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')\n",
        "\n",
        "# Load them later (example)\n",
        "# model = joblib.load('spam_classifier_model.pkl')\n",
        "# tfidf = joblib.load('tfidf_vectorizer.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0Oi40oqBjBP",
        "outputId": "36c675b1-905c-46c8-c187-7f1bf61c8bf3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tfidf_vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    }
  ]
}